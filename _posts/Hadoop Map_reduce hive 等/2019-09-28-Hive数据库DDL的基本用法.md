---
layout:     post
title:     Hive 数据库 DDL 基本用法
subtitle:   大数据处理
date:       2019-09-24
author:     Yi Xia
header-img: img/post-bg-BJJ.jpg
catalog: true
tags:
    - 大数据处理
---

# Hive 数据库 DDL 基本用法
## 实验目的
掌握Hive数据库DDL的基本用法。
## 实验内容
### 1. 数据库
```sql
-- 显示所有数据库
SHOW DATABASES;

-- 显示数据库信息。
DESCRIBE DATABASE default;

-- 显示数据库详细信息，会显示出定义的的dbproperties。
DESCRIBE DATABASE EXTENDED default; 
创建数据库
-- 默认存储路径是：/warehouse/tablespace/managed/hive/*.db
CREATE DATABASE sugon_db; 

-- 避免要创建的数据库已经存在错误，增加 if not exists 判断。
CREATE DATABASE IF NOT EXISTS sugon_db;

-- 创建一个数据库，指定数据库在 HDFS 上存放的位置。
CREATE DATABASE sugon_db1 LOCATION '/tmp/sugon_db.db'; 
切换数据库
-- 查询当前使用的数据库名。
SELECT current_database();

-- 切换当前使用的数据库
USE sugon_db;

-- 可以通过关键字DEFAULT代替数据库名，切换回默认数据库。
USE DEFAULT;
删除数据库
-- 删除空数据库
DROP DATABASE sugon_db; 

-- 如果删除的数据库不存在，最好采用 if exists 判断数据库是否存在。
DROP DATABASE IF EXISTS sugon_db; 

-- 如果数据库不为空，可以使用 cascade 强制删除。
DROP DATABASE sugon_db CASCADE;
修改数据库
-- 修改数据库的 DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息，并再次查看。
ALTER DATABASE sugon_db1 SET DBPROPERTIES('createtime'='20190501');
DESCRIBE DATABASE EXTENDED sugon_db1;

--修改数据库的HDFS位置（需要使用HDFS的绝对路径），但并不会移动原来的数据，只是新增加的数据会添加到新的位置。
ALTER DATABASE sugon_db1 SET LOCATION 'hdfs://local
```
#### 实验测试
![-w1552](/img/blog_img/15696644776068.jpg)
### 2. 表

```sql
-- 显示当前使用的数据库中的表
SHOW TABLES;

-- 显示指定数据库中的表
SHOW TABLES IN sugon_db1;

-- 显示表的基本信息
DESCRIBE students;

-- 显示表的详细信息
DESCRIBE FORMATTED students;

-- 显示建表语句
SHOW CREATE TABLE students;
创建表
-- 创建一个受管的表
CREATE TABLE students (name VARCHAR(64), age INT, gpa DECIMAL(3,2));

-- 查看受管表的文件存放位置
set hive.metastore.warehouse.dir;

-- 到HDFS上查看表的存放位置 直接在beeline中输入
dfs -ls /user/hive/warehouse;

-- 查看表的类型是受管表（Table Type）
DESCRIBE FORMATTED students;

-- 创建一个外部表
CREATE EXTERNAL TABLE stu(id BIGINT, name STRING, email STRING, addr STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
LOCATION '/tmp/stu';

-- 查看表的类型是受管表（Table Type）
DESCRIBE FORMATTED stu;
分区表操作
# 编辑样例数据
vim ~/generals.txt

# 内容如下：
1    张三    zhangsan@email.com    beijing    10.98    2018-01-01 01:00:00
2    李四    lisi@email.com    qingdao    2.01    1998-01-01 01:00:00
3    王五    wangwu@email.com    jinan    100.98    2019-01-01 01:00:00
4    刘备    liubei@email.com    chongqin    23.56    2010-01-01 01:00:00
5    关羽    guanyu@email.com    beijing    77.88    2011-01-01 01:00:00
6    张飞    zhangfei@email.com    beijing    999.98    2012-01-01 01:00:00
7    马超    machao@email.com        89.98    2012-01-01 01:00:00

-- 创建分区表
CREATE TABLE generals (id BIGINT, 
                       name STRING,
                      email STRING,
                      location STRING,
                      power DOUBLE,
                      create_time TIMESTAMP) 
    PARTITIONED BY (dt STRING, country STRING)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t'
    STORED AS TEXTFILE;

-- 查看分区 
SHOW PARTITIONS generals;

-- 加载数据
LOAD DATA LOCAL INPATH 'generals.txt' INTO TABLE generals PARTITION (dt='2001-01-01', country='cn');

LOAD DATA LOCAL INPATH 'generals.txt' INTO TABLE generals PARTITION (dt='2001-01-02', country='cn');

-- 单分区查询 
SELECT * FROM generals WHERE dt='2001-01-01'; 

-- 多分区联合查询
SELECT * FROM generals WHERE dt='2001-01-01' 
UNION 
SELECT * FROM generals WHERE dt='2001-01-02';

-- 添加分区
ALTER TABLE generals ADD PARTITION(dt='2001-01-03', country='cn');

-- 添加多个分区
ALTER TABLE generals ADD PARTITION(dt='2001-01-04', country='cn') PARTITION(dt='2001-01-05', country='cn'); 

-- 删除单个分区 
ALTER TABLE generals DROP PARTITION (dt='2001-01-01', country='cn');

-- 同时删除多个分区
ALTER TABLE generals DROP PARTITION (dt='2001-01-01', country='cn'), PARTITION (dt='2001-01-02', country='cn');


-- 动态分区
-- （默认false）,表示开启动态分区功能
set hive.exec.dynamic.partition =true;
-- (默认strict),表示允许所有分区都是动态的，否则必须有静态分区字段
set hive.exec.dynamic.partition.mode = nonstrict;

CREATE TABLE dp_generals (id BIGINT, 
                       name STRING,
                      email STRING,
                      power DOUBLE,
                      location STRING) 
    PARTITIONED BY (create_time STRING)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t'
    STORED AS TEXTFILE;
-- 最后一个字段为动态分区字段
insert overwrite table dp_generals select id,name,email,power,location,year(create_time) from generals; 
分桶表操作
-- 创建分桶表
CREATE TABLE bucketed_generals (id INT, name STRING)
CLUSTERED BY(id)
INTO 4 BUCKETS
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;

-- 查看分桶情况(Num Buckets)
DESC FORMATTED bucketed_generals;

-- 导入数据到分桶表中
hdfs dfs -put generals.txt /input/
LOAD DATA INPATH '/input/generals.txt' INTO TABLE bucketed_generals;

-- 查看创建的分桶表中是否分成 4 个桶
dfs -ls /user/hive/warehouse/bucketed_generals/;

-- 对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。 Hive可以通过对表进行抽样来满足这个需求。
-- 查询表bucketed_stu中的数据。
SELECT * FROM bucketed_generals TABLESAMPLE(BUCKET 1 OUT OF 4 ON id);
根据查询创建表
-- 根据查询结果创建表（CTAS，查询的结果会添加到新创建的表中）
CREATE TABLE IF NOT EXISTS students3 AS SELECT * FROM students;

-- 根据已经存在的表结构创建表
CREATE TABLE IF NOT EXISTS students4 LIKE students;
修改表
-- 修改表名
ALTER TABLE students3 RENAME TO stu3;

-- 添加列          
ALTER TABLE students4 ADD COLUMNS(phone STRING);
删除表
-- 截断表
TRUNCATE TABLE stu3;

-- 删除表
DROP TABLE stu3;
```

#### 实验测试
![-w880](/img/blog_img/15696652233774.jpg)
![-w1552](/img/blog_img/15696657491642.jpg)
![-w1552](/img/blog_img/15696666112463.jpg)
![-w931](/img/blog_img/15696668115251.jpg)
![-w1552](/img/blog_img/15696677714204.jpg)
![-w1552](/img/blog_img/15696710113101.jpg)
![-w1552](/img/blog_img/15696712082169.jpg)

#### 表实验时出现的问题及解决措施
- 问题:查询全是 NULL
![-w525](/img/blog_img/15696701311122.jpg)</br>
**原因：分隔符问题，我们建表时，利用的是‘\t’进行分割，但是复制 txt 时，都变成空格了，所以分割出来的都是 NULL
解决办法：把表删了，txt 重新拿制表符分割，然后重新建表，将数据导入**
![-w668](/img/blog_img/15696700859399.jpg)
![-w412](/img/blog_img/15696701061164.jpg)
</br>
**修改前查询**</br>
![-w525](/img/blog_img/15696701311122.jpg)
</br>**修改后查询**![-w753](/img/blog_img/15696701448535.jpg)
- 导入数据到分区桶时，出现了FAILED: SemanticException Cartesian products are disabled for safety reasons.
解决方法：

```shell
set hive.mapred.mode=nonstrict;
```

### 3. 查询

```sql
普通查询
SELECT id, name, email, power FROM generals WHERE id>3 ORDER BY power;

# 别名
SELECT name AS my_name, power my_power FROM generals;
JOIN
-- 内连接 只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。
SELECT g.name, g.location, l.code, l.name FROM generals g JOIN locations l ON g.location= l.code;

-- 左外连接 JOIN操作符左边表中符合 WHERE 子句的所有记录将会被返回。
SELECT g.name, g.location, l.code, l.name FROM generals g LEFT JOIN locations l ON g.location= l.code;

-- 右外连接 JOIN 操作符右边表中符合 WHERE 子句的所有记录将会被返回。
SELECT g.name, g.location, l.code, l.name FROM generals g RIGHT JOIN locations l ON g.location= l.code;

-- 满外连接 将会返回所有表中符合 WHERE 语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用 NULL 值替代。
SELECT g.name, g.location, l.code, l.name FROM generals g FULL JOIN locations l ON g.location= l.code;

-- 笛卡尔积。
SELECT g.name, g.location, l.code, l.name FROM generals g, locations l;
排序
-- ORDER BY 全局排序
SELECT * FROM generals ORDER BY id DESC;

-- SORT BY 对于大规模的数据集 order by 的效率非常低。在很多情况下，并不需要全局排序，此时可以使用 sort by。Sort by 为每个 reducer 产生一个排序文件。 每个 Reducer 内部进行排序，对全局结果集来说不是排序
set mapreduce.job.reduces=3;
SELECT * FROM generals SORT BY id;

-- 还有DISTRIBUTE BY、CLUSTER BY，请自行了解
聚合
-- HAVING 与 WHERE 不同点
-- （1） WHERE 后面不能写分组函数，而 HAVING 后面可以使用分组函数。
-- （2） HAVING 只用于 GROUP BY 分组统计语句。
SELECT location, avg(power) FROM generals GROUP BY location; 
```


`我们再创建一个 location 表，并对 general 的数据稍作修改`
![-w1552](/img/blog_img/15696725643097.jpg)
全连接![-w1326](/img/blog_img/15696739451972.jpg)
全局排序
![-w1324](/img/blog_img/15696741309002.jpg)
聚合操作
![-w1330](/img/blog_img/15696741876728.jpg)
## 实验总结
学到了很多东西，增强了自学能力，就是命令太多了，如果要熟练掌握还要大量练习🤟🧐