---
layout:     post   				    # 使用的布局（不需要改）
title:      Enron 邮件大汇总 	# 标题 
subtitle:   安然邮件多角度分析 #副标题
date:       2019-06-25 				# 时间
author:     summer					# 作者
header-img: img/post-bg-miui6.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 项目
---
# Enron 数据多角度分析
**总体框架**

-------

![-w836](/img/15617282157588.jpg)      首先处理给定的邮件数据，对每一封邮件的格式以及内容进行分析，提取每封邮件对应的收件人、发件人、发件时间、邮件主题以及邮件内容等信息，其次利用不同指标计算不同用户通信紧密度，得到通联关系矩阵，用户为节点，通信紧密度为边，然后利用Pagerank算法计算每个节点的PR值，发现关键节点，再用GN算法划分社区；然后利用LDA进行主题抽取分析，做出基于内容的用户情感分析以及邮件主题标注；最后将整个过程整合为一个系统，较为全面的展示本次实验的内容以及成果。


-------
## 数据预览
![-w639](/img/15617283930257.jpg)
<center>**年份预览**</center>

![-w506](/img/15617284173845.jpg)
<center>*时间总体概览*</center>
![-w556](/img/blog_img/15617286406077.jpg)
<center>*词云概览*</center>
## 数据预处理
![-w598](/img/blog_img/15617288281269.jpg)
![-w655](/img/blog_img/15617288581491.jpg)
## 邮件通联关系的挖掘
### 构建通联关系(熵权法)
提取出时间后，使用三个指标对用户通信密度进行度量：通信频度、通信跨度和共享邻居重叠度。其中通信频度是指在指定的一段时间内双方的通信次数，时间单位为天，通信频度越高则双方通信越紧密，通信频度越低则双方通信越稀少；通信跨度是指双方首次通信与末次通信的时间间隔，时间单位为天，通信跨度越大则双方越紧密；共享邻居重叠度指的是两个节点公共邻居节点的个数占他们所有邻居数的比例。
![-w485](/img/blog_img/15617289761908.jpg)
### 利用 Gephi 构建无向图
![3](/img/blog_img/3.jpg)
### Pagerank及有向图的建立
![-w761](/img/blog_img/15617291434886.jpg)
### 社团发现
![1](/img/blog_img/1.jpg)
>GN可以改进出如下:G将全局模块度降为局部模块度； Newman快速算法；Hadoop平台上的DBCHC算法和DBCS算法
![-w465](/img/blog_img/15617291972347.jpg)


## 邮件内容挖掘
### 文本内容的预处理
在进行邮件数据预处理时，已经将每封邮件的主题提取至文件中，要利用LDA主题模型进行处理，首先要对文本进行预处理，需要一系列的分词、去停用词、去除标点、词干提取等操作，将提取出的主题内容进行优化

![-w488](/img/blog_img/15617293738423.jpg)
### LDA 主题提取
![-w889](/img/blog_img/15617294082810.jpg)
![-w899](/img/blog_img/15617294205221.jpg)
从中,我们可以发现,我们分出了 20 个主题,其中对应圆的大小代表了其主题的关键词所占总体的情况,圈的面积越大,对应的的话题占总体的比重越大.话题与话题之间的关系可以通过对应圆圈与圆圈之间的距离来进行刻画,对应话题圆环越近则说明主题于是相近.
	右侧为左侧选中话题的占比情况,我在做 LDA 是对于参数的选择是每个话题 10 个关键词,所以,显示的是对应主题的赐个关键词所占总体此关键词的占比情况,同时左上角可以通过更改对应的参数来度量不同的关系.
### 基于主题的 pagerank
单单使用PageRank存在一定的不足性：PageRank忽略了主题相关性，只是用不同用户通信频度来度量关键性，导致结果的相关性和主体性降低。
在PageRank的向量迭代公式：
![-w615](/img/blog_img/15617295049828.jpg)
根据上面LDA模型得到的主题，在每封邮件中标注出对应的词，并计算出对应主题的匹配度，得到该邮件最为匹配的主题：
![-w795](/img/blog_img/15617295387771.jpg)
## 系统实现
![Syste](/img/blog_img/System1.jpg)
系统版面介绍:
	首先主图是根据我们所得到的发送邮件的关系的出的人物总体架构图,用于方便使用者直观观察所关注人员发送邮件情况.(未来可以根据邮件的内容提取知识,构建知识图谱,从而根据大量的邮件从而挖掘出机构的内在架构关系,这样以后可以实现不只是安然邮件的分析,若收集到其他国家的邮件等数据,也可以从而构建出对应的知识图谱.以上仅是设想)
	左边三个图表分别展示了所有发送邮件的每年概况,以及每年对应月份的变化情况,左下角主要是根据对命名实体的地理情况,识别出主图所选人员的地理位置,从而实现实体和地理位置的相互关联.
	右边的三个图主要为查询界面,将来可以做的工作包括以 Django 为框架,将每篇邮件存入 MongoDB 数据库中,每一篇邮件为一个单元,实现前后端的交互,而不仅是统计界面.

![Syste](/img/blog_img/System2.jpg)
此界面的主要内容是将邮件根据 LDA 分类的类别进行分类,然后分别统计当天和总体的各个主题邮件的情况,以及实时轮播展示对用邮件的情况.
		右侧展示社团发现的情况,我们将他们GN算法的出的社团分为 4 类,分别是 CEO 和董事会,高管,部门经理,普通员工四个类别.
![-w813](/img/blog_img/15617296568446.jpg)
此界面为联动效果,其中左上角为主界面,我们可以通过左上角的图点击对应的人物,得到与他关联的所有人的通联关系,其中大小越大代表对应的关系紧密程度.
	点击右上角的人物,可以得到点击人物发送的所有邮件的词云图(每个人都有一张词语图)和其发送所有邮件的主题流图(每个人都有对应的主图流图),以发现其邮件内容的主题变化.

## 实验总结
本次实验实现了通联紧密度计算、通联关系网络绘制、局部社区发现、文本内容情感分析等内容，但是每部分内容做得都不是很完美，我感觉是每部分的数据预处理方面做得不是很到位，没有一个好的数据也就的不出好的结论。另一方面不足就是没有产生类似于预测的具有很大分析价值的结论，这部分将在以后的学习中多加练习。
