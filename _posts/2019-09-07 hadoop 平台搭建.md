---
layout:     post
title:      Hadoop 平台搭建及基本 hdfs 操作
subtitle:   大数据处理
date:       2018-01-04
author:     Yi Xia
header-img: img/post-bg-BJJ.jpg
catalog: true
tags:
    - 大数据处理
---
- [Hadoop 平台搭建及基本操作](# Hadoop 平台搭建及基本操作)  
- [Hdfs 基本操作](## Hdfs基本操作)  
- [Eclipse 远程调试Hadoop 程序](## Eclipse 远程调试Hadoop 程序)  




# Hadoop 平台搭建及基本操作
> centos 数量：6
  windows 数量：1 (用 finalshell 连接 6 台 centos）
  maobook 数量：1 （java 操作 hdfs）

## Hadoop 平台的搭建
### 分布式机器
![-w764](/img/blog_img/15678343280016.jpg)
### 集群搭建形式
Hadoop环境搭建分为三种形式：单机模式、伪分布式模式、完全分布模式

单机模式—— 在一台单机上运行，没有分布式文件系统，而是直接读写本地操作系统的文件系统。

伪分布式—— 也是在一台单机上运行，但不同的是Java进程模仿分布式运行中的各类节点。即一台机器上，既当NameNode，又当DataNode，或者说既是JobTracker又是TaskTracker。没有所谓的在多台机器上进行真正的分布式计算，故称为“伪分布式”。

完全分布式—— 真正的分布式，由3个及以上的实体机或者虚拟机组成的机群。一个Hadoop集群环境中，NameNode，SecondaryName和DataNode是需要分配在不同的节点上，也就需要三台服务器。

**前两种模式一般用在开发或测试环境下，生产环境下都是搭建完全分布式模式。**

从分布式存储的角度来说，集群中的节点由一个NameNode和若干个DataNode组成，另有一个SecondaryNameNode作为NameNode的备份。

从分布式应用的角度来说，集群中的节点由一个JobTracker和若干个TaskTracker组成。JobTracker负责任务的调度，TaskTracker负责并行执行任务。TaskTracker必须运行在DataNode上，这样便于数据的本地计算。JobTracker和NameNode则无须在同一台机器上。
### 搭建步骤
网上这种教程超级多，此处放一个[详细的连接地址](https://blog.csdn.net/sjmz30071360/article/details/79889055)
简述一下搭建的流程：
* 每台机器安装&配置JDK（1台做好后，克隆出其它机器）
* 上传&配置hadoop（配置完master后，将/usr/hadoop/整个目录内容copy到其它机器）
* 修改每台机器主机名(hostname) ，便于后面 hadoop 环境搭建
* 配置ssh，实现无密码登录
* 修改 hadoop 中的 hdfs-site.xml和 core-site.xml文件
* 启动 hadoop

### 那些年，那些 hadoop，那些坑
- 别问我为什么，我也不知道为什么要去掉，但不去掉就是错😢
![-w227](/img/blog_img/15682001213320.jpg)
- java 的环境，不要用 centos 原来的java SE，自己下一个 java1.8，再 scp 到每一个机器中。配一下环境变量，source 一下
  有时候每一次都尽可能的 source 一下，经常又恢复以前的情况了
  
- 不要多次 hadoop namenode -format ,造成 DataNode 和NameNode 的 version 不一样，造成两者连接失败
- 在两者之间切换时，若遇到无法正常启动的情况，可以删除所涉及节点的临 时文件夹，这样虽然之前的数据会被删掉，但能保证集群正确启动。所以如果 集群以前能启动，但后来启动不了，特别是 DataNode 无法启动，不妨试着删 除所有节点(包括 Slave 节点)上的 /usr/local/hadoop/tmp 文件夹，再重新 执行一次   ，再次启动试试。

### hadoop搭建结果
namenode（10.113.10.11）：
![-w766](/img/blog_img/15678353254973.jpg)
DataNode（其他 5 台）
![-w763](/img/blog_img/15678353578430.jpg)



## Hdfs基本操作
### 概述
HDFS Shell命令允许使用命令行在HDFS存储中进行文件夹和文件操作。
如文件夹的增删改查、文件的增删改查等。
### 命令格式
hdfs dfs -操作命令 参数
前面的【hdfs dfs -】部分是固定的，后面的【操作命令 参数】部分是变化的
### 下面结合一些老师给的文档以及网上的资料，实践了一下常见的命令
hdfs dfs -mkdir /abc #创建名为/abc的文件夹
![-w763](/img/blog_img/15678563032275.jpg)

hdfs dfs -ls / 0 #列出根目录中的内容

hdfs dfs -ls -R / #递归列出多层文件夹的内容

hdfs dfs -put /etc/hosts /abc/hosts #把Linux系统中/etc/hosts文件上传到HDFS中

hdfs dfs -appendToFile /etc/hosts /abc/hosts

**向文件中追加内容**

hdfs dfs -checksum /abc/hosts #查看文件的MD5值

hdfs dfs -du -h / #查看文件/文件夹的大小

**-h以人类友好的方式显示大小（过大时带单位）**

hdfs dfs -get /abc/hosts ./hosts #把HDFS中的文件下载到本地Linux中

**注意./hosts是下载后保存到本地的位置**

hdfs dfs -cat /abc/hosts #查看HDFS中文本文件的内容

**注意：只能查看文件文件**

hdfs dfs -tail /abc/hosts #列出文件结尾处1KB的文件内容

hdfs dfs -mv /abc/hosts /abc/xyz #修改文件名字或移动位置

hdfs dfs -cp /abc/xyz /abc/hosts #复制文件

hdfs dfs -find / -name xyz #查找名字为xyz的文件的位置

hdfs dfs -rmdir /abc #删除名为/abc的文件夹

**注意：如果其中还有文件则不能删除**

hdfs dfs -rm /abc/hosts #删除文件

hdfs dfs -rm -r /abc #递归删除文件/文件夹，文件夹中有文件也能删除

hdfs dfs -df #查看HDFS文件系统的磁盘使用情况
## Eclipse 远程调试Hadoop 程序
网上这种教程超级多，此处放一个[详细的连接地址](https://www.cnblogs.com/999-/p/6840682.html)

1. 下载并安装eclipse
2. https://github.com/winghc/hadoop2x-eclipse-plugin
3. 下载插件到eclipse的插件目录 
4. 配置hadoop 安装的目录
![-w896](/img/blog_img/15678360729249.jpg)
1. 配置配置文件
![-w912](/img/blog_img/15678361163717.jpg)
1. 启动 hadoop
2. 新建MapReduce任务
 File->New->project->Map/Reduce Project->Next
 ![-w687](/img/blog_img/15678361848977.jpg)
8. 项目搭建完毕
![-w1440](/img/blog_img/15678362121958.jpg)
